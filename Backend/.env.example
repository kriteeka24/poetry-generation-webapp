# Flask Backend Configuration
# Copy this file to .env and adjust values as needed

# Server settings
PORT=5000
HOST=0.0.0.0
DEBUG=false

# Set to "0" to use real model inference (requires GPU recommended)
# Set to "1" for development/testing with fake responses
FAKE_MODE=0

# Hugging Face model identifiers
HF_GPT2_MODEL=kriteekathapa/gpt2-poems-finetuned-v1
HF_LSTM_MODEL=kriteekathapa/lstm-poem-generator-v1

# Optional: Hugging Face API token (if models are private)
# HF_TOKEN=your_huggingface_token_here

# Device configuration: "cuda", "cpu", or "auto"
DEVICE=auto
