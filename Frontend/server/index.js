// Lightweight example server for local development.
// - Quick fake response mode for UI development
// - Example using Hugging Face Inference API (uncomment and set HF_API_TOKEN)

const express = require("express");
const bodyParser = require("body-parser");
const fetch = require("node-fetch"); // npm i node-fetch@2 if needed

const app = express();
app.use(bodyParser.json());
const PORT = process.env.PORT || 5000;

// Toggle to true to use fake responses for quick UI testing
const FAKE_MODE = true;

// Example: If you want to forward to Hugging Face Inference API, set HF_API_TOKEN env var
const HF_API_TOKEN = process.env.HF_API_TOKEN || "";

app.post("/api/generate", async (req, res) => {
  try {
    const { model, prompt, max_length, temperature } = req.body;
    if (!model || !prompt)
      return res.status(400).json({ error: "Missing model or prompt" });

    if (FAKE_MODE) {
      // Return a simple deterministic fake text (useful for UI dev)
      const fake = `${prompt}\n\n(Generated by ${model.toUpperCase()} â€” length=${max_length}, temp=${temperature})\n\nRoses are code,\nLines in a row,\nBytes in the night,\nSoftly they glow.`;
      return res.json({ generated_text: fake });
    }

    // Example: call Hugging Face text generation (adjust endpoint and payload for your model)
    if (!HF_API_TOKEN) {
      return res
        .status(500)
        .json({ error: "HF_API_TOKEN not set and FAKE_MODE is false" });
    }

    const hfModel = model === "gpt2" ? "gpt2" : "your-lstm-served-model"; // change as needed
    const hfEndpoint = `https://api-inference.huggingface.co/models/${hfModel}`;
    const hfRes = await fetch(hfEndpoint, {
      method: "POST",
      headers: {
        Authorization: `Bearer ${HF_API_TOKEN}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        inputs: prompt,
        parameters: {
          max_new_tokens: Math.min(1024, max_length),
          temperature: Math.max(0.0, Math.min(2.0, temperature)),
        },
      }),
    });

    if (!hfRes.ok) {
      const errText = await hfRes.text();
      return res.status(500).json({ error: "Hugging Face error: " + errText });
    }

    const hfJson = await hfRes.json();
    // Hugging Face returns an array with generated_text in some cases
    const generated = Array.isArray(hfJson)
      ? hfJson[0]?.generated_text ?? ""
      : hfJson?.generated_text ?? "";
    return res.json({ generated_text: generated });
  } catch (err) {
    console.error(err);
    return res.status(500).json({ error: String(err) });
  }
});

app.listen(PORT, () => {
  console.log(`Server listening on http://localhost:${PORT}`);
  console.log(
    "POST /api/generate with { model, prompt, max_length, temperature }"
  );
});
